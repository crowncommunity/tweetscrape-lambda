service: tweetscraper

plugins:
  - serverless-plugin-ifelse
  - serverless-offline

custom:
    is_local: ${env:IS_LOCAL, ""}
    is_offline: ${env:IS_OFFLINE, ""}
    serverless-offline:
        host: 0.0.0.0
    Stage: ${opt:stage, 'dev'}
    ServiceName: tweetscraper
    AccountId:
        Ref: "AWS::AccountId"
    TweetBucket: ${self:custom.ServiceName}-bucket
    SubmissionQueue: ${self:custom.ServiceName}-submissions
    ScrapeQueue: ${self:custom.ServiceName}-queue
    ScrapeSearch: ${self:custom.ServiceName}-search
    ScrapeThrottleTTL: 1800
    ESEndPoint:
        Fn::GetAtt:
            - ElasticSearchInstance
            - DomainEndpoint
    ESRegion:
        Ref: "AWS::Region"
    local: ${file(./local-env.yml)}
    serverlessIfElse:
        -   If: '"x${self:custom.is_local}" == "x" && "x${self:custom.is_offline}" == "x"'
            Set:
                provider.environment.ELASTIC_HOST: ${self:custom.ESEndPoint}
                provider.environment.ELASTIC_REGION: ${self:custom.ESRegion}
                provider.environment.SCRAPE_LIMIT: ${self:custom.ScrapeThrottleTTL}
                provider.environment.ACCOUNT_ID: ${self:custom.AccountId}

provider:
    name: aws
    stage: ${self:custom.Stage}
    runtime: nodejs8.10
    memorySize: 128
    environment:
        SCRAPE_URL: "http://tweetscraper-env.dbdzfu5nui.us-west-1.elasticbeanstalk.com/tweet/"
        INDEX_NAME: ${self:custom.ScrapeSearch}-index
        S3_SAVE_BUCKET: ${self:custom.TweetBucket}
        SUBMIT_QUEUE: ${self:custom.SubmissionQueue}
        SCRAPE_QUEUE: ${self:custom.ScrapeQueue}
        ELASTIC_HOST: ${self:custom.local.ESEndPoint}
        ELASTIC_REGION: ${self:custom.local.ESRegion}
        SCRAPE_LIMIT: ${self:custom.local.ScrapeThrottleTTL}
        ACCOUNT_ID: ${self:custom.local.AccountId}

    iamRoleStatements:
        -   Effect: Allow
            Action:
                - sqs:DeleteMessage
                - sqs:DeleteMessageBatch
                - sqs:ReceiveMessage
                - sqs:SendMessage
                - sqs:SendMessageBatch
                - sqs:GetQueueUrl
                - sqs:GetQueueAttributes
            Resource: arn:aws:sqs:*:*:${self:custom.ScrapeQueue}
        -   Effect: Allow
            Action:
                - "es:ESHttpHead"
                - "es:ESHttpPost"
                - "es:ESHttpGet"
                - "es:ESHttpDelete"
                - "es:ESHttpPut"
                - "es:DescribeElasticsearchDomain"
                - "es:DescribeElasticsearchDomainConfig"
            Resource: arn:aws:es:*:*:domain/*
        -   Effect: Allow
            Action:
                - s3:*
            Resource:
                - arn:aws:s3:::${self:custom.TweetBucket}/*
                - arn:aws:s3:::${self:custom.TweetBucket}

functions:
    index:
        handler: handler.hello
        events:
            - http: GET hello
    scrape:
        handler: handler.scrape
        events:
            - sqs:
                arn:
                    Fn::GetAtt:
                        - ScrapeQueue
                        - Arn
                batchSize: 10
        reservedConcurrency: 3
    enqueue:
        handler: handler.enqueue
        events:
            - http:
                method: POST
                path: enqueue
                cors: true
                # authorizer:
                #     type: aws_iam
                request:
                    parameters:
                        querystrings:
                            tweet: false
    search:
        # search by username (screenName, mentions, quoteTweet.screenName, permaLink?)
        # search by tweetId (tweetId, conversationId, permaLink?)
        # search by text
        # search by tweet ts
        # search by scrape ts
        # search by tags (hashtags?)
        #  usernames/tweets_by/mentioning
        #  tweet_content
        #  tweeter_name
        #  tags/hashtags
        #  in_reply_to/quoting
        handler: handler.search
        events:
            - http:
                method: GET
                path: search
                cors: true
                request:
                    parameters:
                        querystrings:
                            q: true

    submit:
        # public, must have lots of sanity checking ... maybe isomorphic-ish to prevent scripting?
        handler: handler.submit
        events:
            - http:
                method: POST
                path: submit
                cors: true
                request:
                    headers:
                        Content-Type: application/json
                    parameters:
                        querystrings:
                            tweet: true
            - http:
                method: GET
                path: submit/{tweet+}
                cors: true
                request:
                    headers:
                        Content-Type: application/json
                    parameters:
                        paths:
                            tweet: false
                        querystrings:
                            tweet: false
    submissions:
        handler: handler.submissions
        events:
            - http:
                method: GET
                path: submissions
                cors: true
                request:
                    headers:
                        Content-Type: application/json
                    parameters:
                        querystrings:
                            limit: false
    deleteSubmissions:
        handler: handler.deleteSubmssions
        events:
            - http:
                method: DELETE
                path: submissions
                cors: true
                request:
                    headers:
                        Content-Type: application/json

    # tweet:
        # direct to S3, public
    # dedupe
        # triggered? or scheduled maybe
        # walks the queue looking for dupes and issues delete/messagevisibility as needed

# maybe
# if a submitted tweet is proven well formed, check if it already exists in ES


resources:
    Resources:
        ScrapeQueue:
            Type: AWS::SQS::Queue
            Properties:
                QueueName: ${self:custom.ScrapeQueue}
                VisibilityTimeout: 30
                MessageRetentionPeriod: 345600
        SubmissionQueue:
            Type: AWS::SQS::Queue
            Properties:
                QueueName: ${self:custom.SubmissionQueue}
                VisibilityTimeout: 900
                MessageRetentionPeriod: 1209600
        TweetImageBucket:
            Type: AWS::S3::Bucket
            Properties:
                BucketName: ${self:custom.TweetBucket}
                VersioningConfiguration:
                    Status: Enabled
                CorsConfiguration:
                    CorsRules:
                        -   AllowedOrigins:
                                - '*'
                            AllowedHeaders:
                                - '*'
                            AllowedMethods:
                                - GET
                                - PUT
                                - POST
                                - DELETE
                                - HEAD
                            MaxAge: 3000

        TweetImageBucketPolicy:
            Type: AWS::S3::BucketPolicy
            Properties:
                Bucket:
                    Ref: TweetImageBucket
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                        -   Effect: Allow
                            Action: "s3:*"
                            Resource: "arn:aws:s3:::${self:custom.TweetBucket}"
                            Principal:
                                AWS:
                                    Fn::Join:
                                        - ":"
                                        -   - "arn:aws:iam:"
                                            - Ref: 'AWS::AccountId'
                                            - "root"

        ElasticSearchInstance:
            Type: AWS::Elasticsearch::Domain
            Properties:
                DomainName: ${self:custom.ScrapeSearch}
                EBSOptions:
                    EBSEnabled: true
                    VolumeType: gp2
                    VolumeSize: 10
                ElasticsearchClusterConfig:
                    InstanceType: t2.small.elasticsearch
                    InstanceCount: 1
                    DedicatedMasterEnabled: false
                    ZoneAwarenessEnabled: false
                ElasticsearchVersion: 6.4
                AccessPolicies:
                    Version: "2012-10-17"
                    Statement:
                        -   Effect: Allow
                            Action: "es:*"
                            Resource:
                                Fn::Join:
                                    - ":"
                                    -   - "arn:aws:es"
                                        - Ref: 'AWS::Region'
                                        - Ref: 'AWS::AccountId'
                                        - "domain/${self:custom.ScrapeSearch}/*"
                            Principal:
                                AWS:
                                    Fn::Join:
                                        - ":"
                                        -   - "arn:aws:iam:"
                                            - Ref: 'AWS::AccountId'
                                            - "root"
